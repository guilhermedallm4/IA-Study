{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Classificadores HUB IA - UFPEL"
      ],
      "metadata": {
        "id": "VjgGst8bgue9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Precepton originating from the library\n"
      ],
      "metadata": {
        "id": "JRhmEAOLg2E_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "# Carregar a base de dados\n",
        "conjunto_de_dados = load_digits(n_class=10)\n",
        "\n",
        "nomes_rotulo = conjunto_de_dados['target_names']\n",
        "\n",
        "rotulos = conjunto_de_dados['target']\n",
        "\n",
        "nomes_feature = conjunto_de_dados['feature_names']\n",
        "\n",
        "features = conjunto_de_dados['data']\n"
      ],
      "metadata": {
        "id": "CcixdtXYhGVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir o conjunto de dados\n",
        "treino, teste, rotulos_treino, rotulos_teste = train_test_split(features, rotulos, test_size=0.20)\n"
      ],
      "metadata": {
        "id": "TWgt86WSlUm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "# Inicializar nosso classificador\n",
        "p = Perceptron()\n",
        "\n",
        "\n",
        "# Treinar nosso classificador\n",
        "\n",
        "\n",
        "modelo = p.fit(treino, rotulos_treino)\n",
        "\n",
        "modelo.get_params()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzXdICzKmAz1",
        "outputId": "6104a9ad-d8b6-4e88-8c4b-d22ac9999436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.0001,\n",
              " 'class_weight': None,\n",
              " 'early_stopping': False,\n",
              " 'eta0': 1.0,\n",
              " 'fit_intercept': True,\n",
              " 'l1_ratio': 0.15,\n",
              " 'max_iter': 1000,\n",
              " 'n_iter_no_change': 5,\n",
              " 'n_jobs': None,\n",
              " 'penalty': None,\n",
              " 'random_state': 0,\n",
              " 'shuffle': True,\n",
              " 'tol': 0.001,\n",
              " 'validation_fraction': 0.1,\n",
              " 'verbose': 0,\n",
              " 'warm_start': False}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "alpha: É um hiperparâmetro que controla a força da regularização (penalização) aplicada ao modelo. Valores maiores de alpha aumentam a penalização.\n",
        "\n",
        "class_weight: Define o peso das classes no modelo. Quando definido como None, todas as classes têm o mesmo peso. Pode ser usado para tratar desequilíbrios de classe.\n",
        "\n",
        "early_stopping: Se definido como True, permite que o treinamento pare antecipadamente quando a métrica de validação não melhora. É comum em algoritmos iterativos para economizar tempo de treinamento.\n",
        "\n",
        "eta0: Taxa de aprendizado inicial para o SGD (gradiente descendente estocástico).\n",
        "\n",
        "fit_intercept: Indica se um termo de intercepção (bias) deve ser ajustado no modelo.\n",
        "\n",
        "l1_ratio: Parâmetro que controla a mistura de regularização L1 e L2. Um valor de 0 corresponde à regularização L2, um valor de 1 corresponde à regularização L1 e valores no meio representam uma combinação.\n",
        "\n",
        "max_iter: Número máximo de iterações ou épocas durante o treinamento.\n",
        "\n",
        "n_iter_no_change: Número de iterações sem melhoria na métrica de validação após o qual o treinamento é interrompido (quando early_stopping é definido como True).\n",
        "\n",
        "n_jobs: Número de trabalhadores (núcleos da CPU) a serem usados durante o treinamento. Quando definido como None, o número padrão de núcleos é usado.\n",
        "\n",
        "penalty: Tipo de penalização a ser aplicado ao modelo. Pode ser 'l1', 'l2' ou None.\n",
        "\n",
        "random_state: Semente para a geração de números aleatórios, o que torna os resultados reproduzíveis.\n",
        "\n",
        "shuffle: Se definido como True, os dados de treinamento são embaralhados aleatoriamente antes de cada iteração.\n",
        "\n",
        "tol: Tolerância para parar o treinamento quando a mudança nos parâmetros do modelo for menor que esse valor.\n",
        "\n",
        "validation_fraction: A fração dos dados de treinamento a serem usados como conjunto de validação quando early_stopping é definido como True.\n",
        "\n",
        "verbose: Controle do nível de informações de depuração durante o treinamento. Um valor maior indica mais informações verbais.\n",
        "\n",
        "warm_start: Se definido como True, o modelo é treinado com os pesos iniciais dos resultados anteriores.\n",
        "\n",
        "Esses parâmetros são usados para ajustar o comportamento do modelo durante o treinamento e podem afetar significativamente o desempenho e o comportamento do modelo. Os valores específicos fornecidos para esses parâmetros determinarão como o modelo é treinado e como ele se comporta durante o processo de ajuste. A seleção adequada de hiperparâmetros é uma parte importante do desenvolvimento de modelos de aprendizado de máquina."
      ],
      "metadata": {
        "id": "9j5YVqwboM22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazer previsões\n",
        "previsoes = modelo.predict(teste)\n",
        "print(previsoes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNF8EFTbm8Sl",
        "outputId": "335666a3-a5ce-4eab-af6f-b7f95e775890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 8 9 9 4 5 0 3 4 5 2 3 0 6 0 2 3 8 0 1 7 5 2 2 0 4 6 1 3 1 2 1 6 7 1 0 0\n",
            " 8 1 4 5 9 7 8 0 1 1 3 2 2 0 6 0 8 4 0 7 3 8 3 4 2 7 5 0 2 2 9 6 4 4 7 0 6\n",
            " 2 3 0 3 1 7 7 9 7 1 0 2 7 6 6 4 2 1 4 4 1 1 4 9 2 8 1 0 4 7 0 4 2 7 1 0 1\n",
            " 1 4 4 3 2 7 2 1 5 5 1 1 4 3 1 9 1 6 3 6 2 3 6 3 0 6 1 0 3 3 8 1 7 8 1 1 3\n",
            " 5 9 1 9 1 2 7 6 6 9 4 5 9 0 7 4 3 6 4 2 7 3 5 0 7 1 3 2 8 3 0 0 9 1 6 0 3\n",
            " 8 4 8 6 0 3 7 7 8 2 1 9 4 8 4 3 1 6 6 7 1 1 8 0 4 4 7 7 3 3 9 1 4 1 5 1 4\n",
            " 3 2 7 0 5 5 2 6 3 3 1 6 8 2 2 1 6 7 7 7 2 5 3 2 9 2 6 3 5 0 7 0 6 4 8 1 7\n",
            " 7 4 4 1 6 9 5 6 0 3 0 7 2 7 4 4 6 3 4 6 0 6 7 2 9 3 2 9 5 5 2 2 3 4 1 0 3\n",
            " 2 5 3 7 4 1 8 3 0 8 5 7 1 0 0 4 5 8 5 8 8 4 8 1 5 8 0 9 2 0 4 1 9 0 4 3 1\n",
            " 4 6 9 5 9 3 0 1 5 6 2 7 5 6 0 3 6 4 8 5 2 0 6 6 3 9 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Geralmente, após treinar um modelo de aprendizado de máquina, é importante fazer previsões em dados de teste ou dados não vistos para avaliar o desempenho do modelo e verificar como ele generaliza para novos dados. As previsões podem ser usadas para várias tarefas, como classificação, regressão ou qualquer outra tarefa para a qual o modelo foi treinado."
      ],
      "metadata": {
        "id": "UH0ye0RooGkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(modelo, features, rotulos, cv=5, scoring='accuracy')\n",
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKlPoIzanZkv",
        "outputId": "74d51c8b-4f7e-4ffd-b1fd-8f205fecb61a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.88055556, 0.83888889, 0.90807799, 0.94986072, 0.8718663 ])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "scores = cross_val_score(modelo, features, rotulos, cv=5, scoring='accuracy'): O código executa a validação cruzada usando os seguintes parâmetros:\n",
        "\n",
        "modelo: É o modelo de aprendizado de máquina que você deseja avaliar.\n",
        "features: São as características (dados) usadas para treinar e avaliar o modelo.\n",
        "rotulos: São os rótulos (classes) correspondentes às amostras.\n",
        "cv=5: Indica que a validação cruzada será realizada em 5 dobras (ou divisões). Isso significa que os dados serão divididos em 5 partes iguais e o modelo será treinado e testado 5 vezes, usando diferentes combinações de treinamento e teste.\n",
        "scoring='accuracy': Define a métrica de avaliação a ser usada, que é a acurácia neste caso. Isso significa que o desempenho do modelo será avaliado com base na proporção de previsões corretas.\n",
        "\n",
        "Ao imprimir a variável scores, você terá uma lista de pontuações de acurácia para cada dobra da validação cruzada. Isso permite avaliar o desempenho do modelo de forma mais abrangente, levando em consideração diferentes divisões dos dados. Geralmente, você pode calcular a média dessas pontuações para obter uma estimativa geral do desempenho do modelo."
      ],
      "metadata": {
        "id": "9_rXoOP-pALj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Avaliar o modelo\n",
        "print(accuracy_score(rotulos_teste, previsoes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxZlanigngCH",
        "outputId": "9af32bd1-07b2-403a-c1f9-527ce89516b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9305555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A função accuracy_score calcula a acurácia comparando as previsões com os rótulos verdadeiros e retorna um valor que representa a porcentagem de previsões corretas. Esse valor é impresso no console usando print, o que permite avaliar o desempenho do modelo em termos de acurácia. Quanto maior a acurácia, melhor o modelo está em fazer previsões corretas."
      ],
      "metadata": {
        "id": "ioRRipsCooEg"
      }
    }
  ]
}